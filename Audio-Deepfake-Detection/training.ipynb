{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Path to dataset\n",
    "train_real_directory = r\"C:/Users/shikh/OneDrive/Desktop/Audio Detection/dataset/for-2sec/for-2seconds/training/real\"\n",
    "train_fake_directory = r\"C:/Users/shikh/OneDrive/Desktop/Audio Detection/dataset/for-2sec/for-2seconds/training/fake\"\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, real_path, fake_path, target_length=16000, n_mfcc=20, fixed_time_steps=101):\n",
    "        self.real_files = [os.path.join(real_path, f) for f in os.listdir(real_path) if f.endswith(\".wav\")]\n",
    "        self.fake_files = [os.path.join(fake_path, f) for f in os.listdir(fake_path) if f.endswith(\".wav\")]\n",
    "        self.files = [(file, 0) for file in self.real_files] + [(file, 1) for file in self.fake_files]  # 0 = real, 1 = fake\n",
    "        self.target_length = target_length\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.fixed_time_steps = fixed_time_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path, label = self.files[idx]\n",
    "        \n",
    "        # Load and fix audio length\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        audio = librosa.util.fix_length(audio, size=self.target_length)\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=self.n_mfcc, n_fft=512, hop_length=160)\n",
    "        \n",
    "        # Pad or truncate to fixed time steps\n",
    "        if mfcc.shape[1] < self.fixed_time_steps:\n",
    "            mfcc = np.pad(mfcc, ((0, 0), (0, self.fixed_time_steps - mfcc.shape[1])))\n",
    "        else:\n",
    "            mfcc = mfcc[:, :self.fixed_time_steps]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        mfcc = torch.FloatTensor(mfcc)  # Shape: [n_mfcc, time_steps]\n",
    "        label = torch.LongTensor([label])  # Ensure label is a tensor\n",
    "\n",
    "        return mfcc, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC Shape: torch.Size([16, 20, 101]), Label: tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = AudioDataset(train_real_directory, train_fake_directory)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Check if dataset loads correctly\n",
    "for mfcc, label in train_loader:\n",
    "    print(f\"MFCC Shape: {mfcc.shape}, Label: {label}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class FakeAudioDetector(nn.Module):\n",
    "    def __init__(self, n_mfcc=20, time_steps=101):\n",
    "        super(FakeAudioDetector, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Calculate flattened size dynamically\n",
    "        self.flattened_size = self._get_conv_output(n_mfcc, time_steps)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Binary classification (real/fake)\n",
    "\n",
    "    def _get_conv_output(self, n_mfcc, time_steps):\n",
    "        dummy_input = torch.randn(1, 1, n_mfcc, time_steps)\n",
    "        with torch.no_grad():\n",
    "            x = self.pool(torch.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            return x.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FakeAudioDetector().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 16.2962\n",
      "Epoch 1, Batch 20, Loss: 1.8498\n",
      "Epoch 1, Batch 30, Loss: 0.7243\n",
      "Epoch 1, Batch 40, Loss: 0.6616\n",
      "Epoch 1, Batch 50, Loss: 0.6859\n",
      "Epoch 1, Batch 60, Loss: 0.6801\n",
      "Epoch 1, Batch 70, Loss: 0.6384\n",
      "Epoch 1, Batch 80, Loss: 0.6312\n",
      "Epoch 1, Batch 90, Loss: 0.6141\n",
      "Epoch 1, Batch 100, Loss: 0.5657\n",
      "Epoch 1, Batch 110, Loss: 0.5392\n",
      "Epoch 1, Batch 120, Loss: 0.5409\n",
      "Epoch 1, Batch 130, Loss: 0.5505\n",
      "Epoch 1, Batch 140, Loss: 0.5065\n",
      "Epoch 1, Batch 150, Loss: 0.5089\n",
      "Epoch 1, Batch 160, Loss: 0.5110\n",
      "Epoch 1, Batch 170, Loss: 0.4861\n",
      "Epoch 1, Batch 180, Loss: 0.4351\n",
      "Epoch 1, Batch 190, Loss: 0.3986\n",
      "Epoch 1, Batch 200, Loss: 0.4729\n",
      "Epoch 1, Batch 210, Loss: 0.4912\n",
      "Epoch 1, Batch 220, Loss: 0.3621\n",
      "Epoch 1, Batch 230, Loss: 0.3997\n",
      "Epoch 1, Batch 240, Loss: 0.3741\n",
      "Epoch 1, Batch 250, Loss: 0.4416\n",
      "Epoch 1, Batch 260, Loss: 0.5786\n",
      "Epoch 1, Batch 270, Loss: 0.4319\n",
      "Epoch 1, Batch 280, Loss: 0.3737\n",
      "Epoch 1, Batch 290, Loss: 0.3990\n",
      "Epoch 1, Batch 300, Loss: 0.3740\n",
      "Epoch 1, Batch 310, Loss: 0.4169\n",
      "Epoch 1, Batch 320, Loss: 0.3573\n",
      "Epoch 1, Batch 330, Loss: 0.4151\n",
      "Epoch 1, Batch 340, Loss: 0.3285\n",
      "Epoch 1, Batch 350, Loss: 0.3040\n",
      "Epoch 1, Batch 360, Loss: 0.2561\n",
      "Epoch 1, Batch 370, Loss: 0.4718\n",
      "Epoch 1, Batch 380, Loss: 0.3631\n",
      "Epoch 1, Batch 390, Loss: 0.3041\n",
      "Epoch 1, Batch 400, Loss: 0.4022\n",
      "Epoch 1, Batch 410, Loss: 0.3573\n",
      "Epoch 1, Batch 420, Loss: 0.3244\n",
      "Epoch 1, Batch 430, Loss: 0.4143\n",
      "Epoch 1, Batch 440, Loss: 0.3775\n",
      "Epoch 1, Batch 450, Loss: 0.4525\n",
      "Epoch 1, Batch 460, Loss: 0.3635\n",
      "Epoch 1, Batch 470, Loss: 0.3822\n",
      "Epoch 1, Batch 480, Loss: 0.3182\n",
      "Epoch 1, Batch 490, Loss: 0.4339\n",
      "Epoch 1, Batch 500, Loss: 0.3567\n",
      "Epoch 1, Batch 510, Loss: 0.2924\n",
      "Epoch 1, Batch 520, Loss: 0.3350\n",
      "Epoch 1, Batch 530, Loss: 0.2792\n",
      "Epoch 1, Batch 540, Loss: 0.2564\n",
      "Epoch 1, Batch 550, Loss: 0.2852\n",
      "Epoch 1, Batch 560, Loss: 0.2775\n",
      "Epoch 1, Batch 570, Loss: 0.2808\n",
      "Epoch 1, Batch 580, Loss: 0.3701\n",
      "Epoch 1, Batch 590, Loss: 0.3629\n",
      "Epoch 1, Batch 600, Loss: 0.2742\n",
      "Epoch 1, Batch 610, Loss: 0.2808\n",
      "Epoch 1, Batch 620, Loss: 0.2491\n",
      "Epoch 1, Batch 630, Loss: 0.2962\n",
      "Epoch 1, Batch 640, Loss: 0.2613\n",
      "Epoch 1, Batch 650, Loss: 0.2525\n",
      "Epoch 1, Batch 660, Loss: 0.2726\n",
      "Epoch 1, Batch 670, Loss: 0.3127\n",
      "Epoch 1, Batch 680, Loss: 0.2552\n",
      "Epoch 1, Batch 690, Loss: 0.3200\n",
      "Epoch 1, Batch 700, Loss: 0.3166\n",
      "Epoch 1, Batch 710, Loss: 0.3198\n",
      "Epoch 1, Batch 720, Loss: 0.2675\n",
      "Epoch 1, Batch 730, Loss: 0.2797\n",
      "Epoch 1, Batch 740, Loss: 0.2392\n",
      "Epoch 1, Batch 750, Loss: 0.3573\n",
      "Epoch 1, Batch 760, Loss: 0.2283\n",
      "Epoch 1, Batch 770, Loss: 0.2016\n",
      "Epoch 1, Batch 780, Loss: 0.2176\n",
      "Epoch 1, Batch 790, Loss: 0.2577\n",
      "Epoch 1, Batch 800, Loss: 0.1974\n",
      "Epoch 1, Batch 810, Loss: 0.2025\n",
      "Epoch 1, Batch 820, Loss: 0.2254\n",
      "Epoch 1, Batch 830, Loss: 0.2114\n",
      "Epoch 1, Batch 840, Loss: 0.2784\n",
      "Epoch 1, Batch 850, Loss: 0.2041\n",
      "Epoch 1, Batch 860, Loss: 0.1855\n",
      "Epoch 1, Batch 870, Loss: 0.2274\n",
      "Epoch 2, Batch 10, Loss: 0.2018\n",
      "Epoch 2, Batch 20, Loss: 0.1995\n",
      "Epoch 2, Batch 30, Loss: 0.2071\n",
      "Epoch 2, Batch 40, Loss: 0.2156\n",
      "Epoch 2, Batch 50, Loss: 0.2608\n",
      "Epoch 2, Batch 60, Loss: 0.2342\n",
      "Epoch 2, Batch 70, Loss: 0.2524\n",
      "Epoch 2, Batch 80, Loss: 0.2321\n",
      "Epoch 2, Batch 90, Loss: 0.1874\n",
      "Epoch 2, Batch 100, Loss: 0.1461\n",
      "Epoch 2, Batch 110, Loss: 0.2079\n",
      "Epoch 2, Batch 120, Loss: 0.1728\n",
      "Epoch 2, Batch 130, Loss: 0.1527\n",
      "Epoch 2, Batch 140, Loss: 0.2017\n",
      "Epoch 2, Batch 150, Loss: 0.1295\n",
      "Epoch 2, Batch 160, Loss: 0.2055\n",
      "Epoch 2, Batch 170, Loss: 0.2298\n",
      "Epoch 2, Batch 180, Loss: 0.1426\n",
      "Epoch 2, Batch 190, Loss: 0.1780\n",
      "Epoch 2, Batch 200, Loss: 0.1924\n",
      "Epoch 2, Batch 210, Loss: 0.2135\n",
      "Epoch 2, Batch 220, Loss: 0.1213\n",
      "Epoch 2, Batch 230, Loss: 0.2615\n",
      "Epoch 2, Batch 240, Loss: 0.1396\n",
      "Epoch 2, Batch 250, Loss: 0.2488\n",
      "Epoch 2, Batch 260, Loss: 0.1229\n",
      "Epoch 2, Batch 270, Loss: 0.2410\n",
      "Epoch 2, Batch 280, Loss: 0.2070\n",
      "Epoch 2, Batch 290, Loss: 0.2016\n",
      "Epoch 2, Batch 300, Loss: 0.0913\n",
      "Epoch 2, Batch 310, Loss: 0.1824\n",
      "Epoch 2, Batch 320, Loss: 0.2750\n",
      "Epoch 2, Batch 330, Loss: 0.1527\n",
      "Epoch 2, Batch 340, Loss: 0.1031\n",
      "Epoch 2, Batch 350, Loss: 0.1892\n",
      "Epoch 2, Batch 360, Loss: 0.3328\n",
      "Epoch 2, Batch 370, Loss: 0.2180\n",
      "Epoch 2, Batch 380, Loss: 0.1675\n",
      "Epoch 2, Batch 390, Loss: 0.1355\n",
      "Epoch 2, Batch 400, Loss: 0.1312\n",
      "Epoch 2, Batch 410, Loss: 0.1005\n",
      "Epoch 2, Batch 420, Loss: 0.0806\n",
      "Epoch 2, Batch 430, Loss: 0.1859\n",
      "Epoch 2, Batch 440, Loss: 0.1998\n",
      "Epoch 2, Batch 450, Loss: 0.2140\n",
      "Epoch 2, Batch 460, Loss: 0.2664\n",
      "Epoch 2, Batch 470, Loss: 0.2109\n",
      "Epoch 2, Batch 480, Loss: 0.1747\n",
      "Epoch 2, Batch 490, Loss: 0.2491\n",
      "Epoch 2, Batch 500, Loss: 0.1856\n",
      "Epoch 2, Batch 510, Loss: 0.2085\n",
      "Epoch 2, Batch 520, Loss: 0.1673\n",
      "Epoch 2, Batch 530, Loss: 0.1916\n",
      "Epoch 2, Batch 540, Loss: 0.0989\n",
      "Epoch 2, Batch 550, Loss: 0.1418\n",
      "Epoch 2, Batch 560, Loss: 0.2377\n",
      "Epoch 2, Batch 570, Loss: 0.1276\n",
      "Epoch 2, Batch 580, Loss: 0.1720\n",
      "Epoch 2, Batch 590, Loss: 0.1695\n",
      "Epoch 2, Batch 600, Loss: 0.2219\n",
      "Epoch 2, Batch 610, Loss: 0.1055\n",
      "Epoch 2, Batch 620, Loss: 0.1740\n",
      "Epoch 2, Batch 630, Loss: 0.1367\n",
      "Epoch 2, Batch 640, Loss: 0.1656\n",
      "Epoch 2, Batch 650, Loss: 0.1896\n",
      "Epoch 2, Batch 660, Loss: 0.2245\n",
      "Epoch 2, Batch 670, Loss: 0.1866\n",
      "Epoch 2, Batch 680, Loss: 0.2185\n",
      "Epoch 2, Batch 690, Loss: 0.1502\n",
      "Epoch 2, Batch 700, Loss: 0.1183\n",
      "Epoch 2, Batch 710, Loss: 0.1055\n",
      "Epoch 2, Batch 720, Loss: 0.2557\n",
      "Epoch 2, Batch 730, Loss: 0.2572\n",
      "Epoch 2, Batch 740, Loss: 0.0863\n",
      "Epoch 2, Batch 750, Loss: 0.1610\n",
      "Epoch 2, Batch 760, Loss: 0.1963\n",
      "Epoch 2, Batch 770, Loss: 0.2177\n",
      "Epoch 2, Batch 780, Loss: 0.1868\n",
      "Epoch 2, Batch 790, Loss: 0.1349\n",
      "Epoch 2, Batch 800, Loss: 0.2086\n",
      "Epoch 2, Batch 810, Loss: 0.1362\n",
      "Epoch 2, Batch 820, Loss: 0.0808\n",
      "Epoch 2, Batch 830, Loss: 0.1171\n",
      "Epoch 2, Batch 840, Loss: 0.0907\n",
      "Epoch 2, Batch 850, Loss: 0.1219\n",
      "Epoch 2, Batch 860, Loss: 0.1287\n",
      "Epoch 2, Batch 870, Loss: 0.1146\n",
      "Epoch 3, Batch 10, Loss: 0.1291\n",
      "Epoch 3, Batch 20, Loss: 0.1330\n",
      "Epoch 3, Batch 30, Loss: 0.0774\n",
      "Epoch 3, Batch 40, Loss: 0.0866\n",
      "Epoch 3, Batch 50, Loss: 0.0995\n",
      "Epoch 3, Batch 60, Loss: 0.0956\n",
      "Epoch 3, Batch 70, Loss: 0.0758\n",
      "Epoch 3, Batch 80, Loss: 0.0316\n",
      "Epoch 3, Batch 90, Loss: 0.0994\n",
      "Epoch 3, Batch 100, Loss: 0.1577\n",
      "Epoch 3, Batch 110, Loss: 0.1268\n",
      "Epoch 3, Batch 120, Loss: 0.1594\n",
      "Epoch 3, Batch 130, Loss: 0.0668\n",
      "Epoch 3, Batch 140, Loss: 0.1236\n",
      "Epoch 3, Batch 150, Loss: 0.1159\n",
      "Epoch 3, Batch 160, Loss: 0.1616\n",
      "Epoch 3, Batch 170, Loss: 0.0683\n",
      "Epoch 3, Batch 180, Loss: 0.1133\n",
      "Epoch 3, Batch 190, Loss: 0.0927\n",
      "Epoch 3, Batch 200, Loss: 0.0477\n",
      "Epoch 3, Batch 210, Loss: 0.1414\n",
      "Epoch 3, Batch 220, Loss: 0.0687\n",
      "Epoch 3, Batch 230, Loss: 0.1257\n",
      "Epoch 3, Batch 240, Loss: 0.1137\n",
      "Epoch 3, Batch 250, Loss: 0.1164\n",
      "Epoch 3, Batch 260, Loss: 0.0630\n",
      "Epoch 3, Batch 270, Loss: 0.1363\n",
      "Epoch 3, Batch 280, Loss: 0.1167\n",
      "Epoch 3, Batch 290, Loss: 0.1732\n",
      "Epoch 3, Batch 300, Loss: 0.1882\n",
      "Epoch 3, Batch 310, Loss: 0.1572\n",
      "Epoch 3, Batch 320, Loss: 0.0562\n",
      "Epoch 3, Batch 330, Loss: 0.0932\n",
      "Epoch 3, Batch 340, Loss: 0.1434\n",
      "Epoch 3, Batch 350, Loss: 0.0715\n",
      "Epoch 3, Batch 360, Loss: 0.2075\n",
      "Epoch 3, Batch 370, Loss: 0.1035\n",
      "Epoch 3, Batch 380, Loss: 0.1276\n",
      "Epoch 3, Batch 390, Loss: 0.1066\n",
      "Epoch 3, Batch 400, Loss: 0.0989\n",
      "Epoch 3, Batch 410, Loss: 0.0829\n",
      "Epoch 3, Batch 420, Loss: 0.0776\n",
      "Epoch 3, Batch 430, Loss: 0.1069\n",
      "Epoch 3, Batch 440, Loss: 0.0675\n",
      "Epoch 3, Batch 450, Loss: 0.0771\n",
      "Epoch 3, Batch 460, Loss: 0.1253\n",
      "Epoch 3, Batch 470, Loss: 0.0772\n",
      "Epoch 3, Batch 480, Loss: 0.0554\n",
      "Epoch 3, Batch 490, Loss: 0.1247\n",
      "Epoch 3, Batch 500, Loss: 0.1159\n",
      "Epoch 3, Batch 510, Loss: 0.2406\n",
      "Epoch 3, Batch 520, Loss: 0.1958\n",
      "Epoch 3, Batch 530, Loss: 0.1537\n",
      "Epoch 3, Batch 540, Loss: 0.1154\n",
      "Epoch 3, Batch 550, Loss: 0.1239\n",
      "Epoch 3, Batch 560, Loss: 0.0970\n",
      "Epoch 3, Batch 570, Loss: 0.0833\n",
      "Epoch 3, Batch 580, Loss: 0.0629\n",
      "Epoch 3, Batch 590, Loss: 0.0271\n",
      "Epoch 3, Batch 600, Loss: 0.0928\n",
      "Epoch 3, Batch 610, Loss: 0.0985\n",
      "Epoch 3, Batch 620, Loss: 0.1280\n",
      "Epoch 3, Batch 630, Loss: 0.1401\n",
      "Epoch 3, Batch 640, Loss: 0.1768\n",
      "Epoch 3, Batch 650, Loss: 0.1088\n",
      "Epoch 3, Batch 660, Loss: 0.0809\n",
      "Epoch 3, Batch 670, Loss: 0.1202\n",
      "Epoch 3, Batch 680, Loss: 0.0562\n",
      "Epoch 3, Batch 690, Loss: 0.0919\n",
      "Epoch 3, Batch 700, Loss: 0.0766\n",
      "Epoch 3, Batch 710, Loss: 0.0804\n",
      "Epoch 3, Batch 720, Loss: 0.1894\n",
      "Epoch 3, Batch 730, Loss: 0.1125\n",
      "Epoch 3, Batch 740, Loss: 0.2149\n",
      "Epoch 3, Batch 750, Loss: 0.1202\n",
      "Epoch 3, Batch 760, Loss: 0.1353\n",
      "Epoch 3, Batch 770, Loss: 0.1210\n",
      "Epoch 3, Batch 780, Loss: 0.1460\n",
      "Epoch 3, Batch 790, Loss: 0.0735\n",
      "Epoch 3, Batch 800, Loss: 0.0844\n",
      "Epoch 3, Batch 810, Loss: 0.0807\n",
      "Epoch 3, Batch 820, Loss: 0.1072\n",
      "Epoch 3, Batch 830, Loss: 0.1834\n",
      "Epoch 3, Batch 840, Loss: 0.0955\n",
      "Epoch 3, Batch 850, Loss: 0.1310\n",
      "Epoch 3, Batch 860, Loss: 0.0823\n",
      "Epoch 3, Batch 870, Loss: 0.0890\n",
      "Epoch 4, Batch 10, Loss: 0.1335\n",
      "Epoch 4, Batch 20, Loss: 0.0842\n",
      "Epoch 4, Batch 30, Loss: 0.0858\n",
      "Epoch 4, Batch 40, Loss: 0.0723\n",
      "Epoch 4, Batch 50, Loss: 0.0433\n",
      "Epoch 4, Batch 60, Loss: 0.0739\n",
      "Epoch 4, Batch 70, Loss: 0.0426\n",
      "Epoch 4, Batch 80, Loss: 0.0416\n",
      "Epoch 4, Batch 90, Loss: 0.0691\n",
      "Epoch 4, Batch 100, Loss: 0.0350\n",
      "Epoch 4, Batch 110, Loss: 0.0522\n",
      "Epoch 4, Batch 120, Loss: 0.0386\n",
      "Epoch 4, Batch 130, Loss: 0.0233\n",
      "Epoch 4, Batch 140, Loss: 0.0624\n",
      "Epoch 4, Batch 150, Loss: 0.0202\n",
      "Epoch 4, Batch 160, Loss: 0.1045\n",
      "Epoch 4, Batch 170, Loss: 0.0619\n",
      "Epoch 4, Batch 180, Loss: 0.1695\n",
      "Epoch 4, Batch 190, Loss: 0.1625\n",
      "Epoch 4, Batch 200, Loss: 0.1243\n",
      "Epoch 4, Batch 210, Loss: 0.0423\n",
      "Epoch 4, Batch 220, Loss: 0.0793\n",
      "Epoch 4, Batch 230, Loss: 0.0400\n",
      "Epoch 4, Batch 240, Loss: 0.0479\n",
      "Epoch 4, Batch 250, Loss: 0.1002\n",
      "Epoch 4, Batch 260, Loss: 0.0537\n",
      "Epoch 4, Batch 270, Loss: 0.0402\n",
      "Epoch 4, Batch 280, Loss: 0.0864\n",
      "Epoch 4, Batch 290, Loss: 0.0712\n",
      "Epoch 4, Batch 300, Loss: 0.1189\n",
      "Epoch 4, Batch 310, Loss: 0.0226\n",
      "Epoch 4, Batch 320, Loss: 0.0538\n",
      "Epoch 4, Batch 330, Loss: 0.0780\n",
      "Epoch 4, Batch 340, Loss: 0.0346\n",
      "Epoch 4, Batch 350, Loss: 0.1072\n",
      "Epoch 4, Batch 360, Loss: 0.0723\n",
      "Epoch 4, Batch 370, Loss: 0.0435\n",
      "Epoch 4, Batch 380, Loss: 0.1483\n",
      "Epoch 4, Batch 390, Loss: 0.1079\n",
      "Epoch 4, Batch 400, Loss: 0.0840\n",
      "Epoch 4, Batch 410, Loss: 0.1314\n",
      "Epoch 4, Batch 420, Loss: 0.0771\n",
      "Epoch 4, Batch 430, Loss: 0.0484\n",
      "Epoch 4, Batch 440, Loss: 0.0504\n",
      "Epoch 4, Batch 450, Loss: 0.1228\n",
      "Epoch 4, Batch 460, Loss: 0.1053\n",
      "Epoch 4, Batch 470, Loss: 0.1492\n",
      "Epoch 4, Batch 480, Loss: 0.1238\n",
      "Epoch 4, Batch 490, Loss: 0.0956\n",
      "Epoch 4, Batch 500, Loss: 0.0697\n",
      "Epoch 4, Batch 510, Loss: 0.1092\n",
      "Epoch 4, Batch 520, Loss: 0.0827\n",
      "Epoch 4, Batch 530, Loss: 0.0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shikh\\AppData\\Local\\Temp\\ipykernel_25908\\548255210.py:27: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_path, sr=16000)\n",
      "c:\\Users\\shikh\\OneDrive\\Desktop\\Audio Detection\\venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 540, Loss: 0.0579\n",
      "Epoch 4, Batch 550, Loss: 0.0458\n",
      "Epoch 4, Batch 560, Loss: 0.1317\n",
      "Epoch 4, Batch 570, Loss: 0.1848\n",
      "Epoch 4, Batch 580, Loss: 0.0625\n",
      "Epoch 4, Batch 590, Loss: 0.1447\n",
      "Epoch 4, Batch 600, Loss: 0.0606\n",
      "Epoch 4, Batch 610, Loss: 0.0629\n",
      "Epoch 4, Batch 620, Loss: 0.0595\n",
      "Epoch 4, Batch 630, Loss: 0.0520\n",
      "Epoch 4, Batch 640, Loss: 0.0860\n",
      "Epoch 4, Batch 650, Loss: 0.0491\n",
      "Epoch 4, Batch 660, Loss: 0.0542\n",
      "Epoch 4, Batch 670, Loss: 0.0698\n",
      "Epoch 4, Batch 680, Loss: 0.0552\n",
      "Epoch 4, Batch 690, Loss: 0.0581\n",
      "Epoch 4, Batch 700, Loss: 0.1069\n",
      "Epoch 4, Batch 710, Loss: 0.0893\n",
      "Epoch 4, Batch 720, Loss: 0.0412\n",
      "Epoch 4, Batch 730, Loss: 0.0596\n",
      "Epoch 4, Batch 740, Loss: 0.0371\n",
      "Epoch 4, Batch 750, Loss: 0.0886\n",
      "Epoch 4, Batch 760, Loss: 0.0835\n",
      "Epoch 4, Batch 770, Loss: 0.1087\n",
      "Epoch 4, Batch 780, Loss: 0.0919\n",
      "Epoch 4, Batch 790, Loss: 0.0346\n",
      "Epoch 4, Batch 800, Loss: 0.0953\n",
      "Epoch 4, Batch 810, Loss: 0.0974\n",
      "Epoch 4, Batch 820, Loss: 0.0623\n",
      "Epoch 4, Batch 830, Loss: 0.1387\n",
      "Epoch 4, Batch 840, Loss: 0.1513\n",
      "Epoch 4, Batch 850, Loss: 0.1370\n",
      "Epoch 4, Batch 860, Loss: 0.1791\n",
      "Epoch 4, Batch 870, Loss: 0.1043\n",
      "Epoch 5, Batch 10, Loss: 0.0616\n",
      "Epoch 5, Batch 20, Loss: 0.0925\n",
      "Epoch 5, Batch 30, Loss: 0.0960\n",
      "Epoch 5, Batch 40, Loss: 0.1276\n",
      "Epoch 5, Batch 50, Loss: 0.0648\n",
      "Epoch 5, Batch 60, Loss: 0.0731\n",
      "Epoch 5, Batch 70, Loss: 0.0693\n",
      "Epoch 5, Batch 80, Loss: 0.0411\n",
      "Epoch 5, Batch 90, Loss: 0.0735\n",
      "Epoch 5, Batch 100, Loss: 0.0733\n",
      "Epoch 5, Batch 110, Loss: 0.0992\n",
      "Epoch 5, Batch 120, Loss: 0.0686\n",
      "Epoch 5, Batch 130, Loss: 0.1088\n",
      "Epoch 5, Batch 140, Loss: 0.0417\n",
      "Epoch 5, Batch 150, Loss: 0.0428\n",
      "Epoch 5, Batch 160, Loss: 0.0366\n",
      "Epoch 5, Batch 170, Loss: 0.0389\n",
      "Epoch 5, Batch 180, Loss: 0.0250\n",
      "Epoch 5, Batch 190, Loss: 0.0606\n",
      "Epoch 5, Batch 200, Loss: 0.0431\n",
      "Epoch 5, Batch 210, Loss: 0.0395\n",
      "Epoch 5, Batch 220, Loss: 0.0323\n",
      "Epoch 5, Batch 230, Loss: 0.0220\n",
      "Epoch 5, Batch 240, Loss: 0.0255\n",
      "Epoch 5, Batch 250, Loss: 0.0574\n",
      "Epoch 5, Batch 260, Loss: 0.0600\n",
      "Epoch 5, Batch 270, Loss: 0.0607\n",
      "Epoch 5, Batch 280, Loss: 0.0975\n",
      "Epoch 5, Batch 290, Loss: 0.0752\n",
      "Epoch 5, Batch 300, Loss: 0.0664\n",
      "Epoch 5, Batch 310, Loss: 0.0699\n",
      "Epoch 5, Batch 320, Loss: 0.0340\n",
      "Epoch 5, Batch 330, Loss: 0.0929\n",
      "Epoch 5, Batch 340, Loss: 0.0556\n",
      "Epoch 5, Batch 350, Loss: 0.0543\n",
      "Epoch 5, Batch 360, Loss: 0.1286\n",
      "Epoch 5, Batch 370, Loss: 0.0781\n",
      "Epoch 5, Batch 380, Loss: 0.0256\n",
      "Epoch 5, Batch 390, Loss: 0.0879\n",
      "Epoch 5, Batch 400, Loss: 0.0371\n",
      "Epoch 5, Batch 410, Loss: 0.0432\n",
      "Epoch 5, Batch 420, Loss: 0.0653\n",
      "Epoch 5, Batch 430, Loss: 0.0638\n",
      "Epoch 5, Batch 440, Loss: 0.0591\n",
      "Epoch 5, Batch 450, Loss: 0.0796\n",
      "Epoch 5, Batch 460, Loss: 0.0376\n",
      "Epoch 5, Batch 470, Loss: 0.0410\n",
      "Epoch 5, Batch 480, Loss: 0.0461\n",
      "Epoch 5, Batch 490, Loss: 0.0525\n",
      "Epoch 5, Batch 500, Loss: 0.0253\n",
      "Epoch 5, Batch 510, Loss: 0.0165\n",
      "Epoch 5, Batch 520, Loss: 0.0094\n",
      "Epoch 5, Batch 530, Loss: 0.0247\n",
      "Epoch 5, Batch 540, Loss: 0.1049\n",
      "Epoch 5, Batch 550, Loss: 0.0177\n",
      "Epoch 5, Batch 560, Loss: 0.0475\n",
      "Epoch 5, Batch 570, Loss: 0.0250\n",
      "Epoch 5, Batch 580, Loss: 0.0298\n",
      "Epoch 5, Batch 590, Loss: 0.0738\n",
      "Epoch 5, Batch 600, Loss: 0.0914\n",
      "Epoch 5, Batch 610, Loss: 0.0646\n",
      "Epoch 5, Batch 620, Loss: 0.0596\n",
      "Epoch 5, Batch 630, Loss: 0.0122\n",
      "Epoch 5, Batch 640, Loss: 0.0762\n",
      "Epoch 5, Batch 650, Loss: 0.0455\n",
      "Epoch 5, Batch 660, Loss: 0.1007\n",
      "Epoch 5, Batch 670, Loss: 0.0816\n",
      "Epoch 5, Batch 680, Loss: 0.0729\n",
      "Epoch 5, Batch 690, Loss: 0.0279\n",
      "Epoch 5, Batch 700, Loss: 0.0299\n",
      "Epoch 5, Batch 710, Loss: 0.0564\n",
      "Epoch 5, Batch 720, Loss: 0.0452\n",
      "Epoch 5, Batch 730, Loss: 0.0432\n",
      "Epoch 5, Batch 740, Loss: 0.0242\n",
      "Epoch 5, Batch 750, Loss: 0.0506\n",
      "Epoch 5, Batch 760, Loss: 0.0251\n",
      "Epoch 5, Batch 770, Loss: 0.0394\n",
      "Epoch 5, Batch 780, Loss: 0.0525\n",
      "Epoch 5, Batch 790, Loss: 0.0829\n",
      "Epoch 5, Batch 800, Loss: 0.0478\n",
      "Epoch 5, Batch 810, Loss: 0.1530\n",
      "Epoch 5, Batch 820, Loss: 0.3042\n",
      "Epoch 5, Batch 830, Loss: 0.2293\n",
      "Epoch 5, Batch 840, Loss: 0.1029\n",
      "Epoch 5, Batch 850, Loss: 0.1260\n",
      "Epoch 5, Batch 860, Loss: 0.0764\n",
      "Epoch 5, Batch 870, Loss: 0.0277\n",
      "ðŸŽ‰ Training Complete!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5  # Adjust as needed\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (mfcc, labels) in enumerate(train_loader):\n",
    "        mfcc = mfcc.unsqueeze(1).to(device)  # Add channel dimension: [batch, 1, 20, 101]\n",
    "        labels = labels.squeeze().to(device)  # Shape: [batch]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(mfcc)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 9:  # Print every 10 batches\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {running_loss/10:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"ðŸŽ‰ Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Accuracy: 98.95%\n"
     ]
    }
   ],
   "source": [
    "## Evaluation metrics\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mfcc, labels in train_loader:\n",
    "        mfcc = mfcc.unsqueeze(1).to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "\n",
    "        outputs = model(mfcc)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"ðŸ“Š Model Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training & Validation Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Paths for training and validation sets\n",
    "train_real_directory = r\"C:/Users/shikh/OneDrive/Desktop/Audio Detection/dataset/for-2sec/for-2seconds/training/real\"\n",
    "train_fake_directory = r\"C:/Users/shikh/OneDrive/Desktop/Audio Detection/dataset/for-2sec/for-2seconds/training/fake\"\n",
    "validation_real_directory = r\"C:/Users/shikh/OneDrive/Desktop/Audio Detection/dataset/for-2sec/for-2seconds/validation/real\"\n",
    "validation_fake_directory = r\"C:/Users/shikh/OneDrive/Desktop/Audio Detection/dataset/for-2sec/for-2seconds/validation/fake\"\n",
    "\n",
    "# Define dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, real_dir, fake_dir, target_length=16000, n_mfcc=20, fixed_time_steps=101):\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.target_length = target_length\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.fixed_time_steps = fixed_time_steps\n",
    "\n",
    "        # Load real audio\n",
    "        for file in os.listdir(real_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                self.files.append(os.path.join(real_dir, file))\n",
    "                self.labels.append(0)  # 0 for real\n",
    "\n",
    "        # Load fake audio\n",
    "        for file in os.listdir(fake_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                self.files.append(os.path.join(fake_dir, file))\n",
    "                self.labels.append(1)  # 1 for fake\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.files[idx]\n",
    "        label = torch.LongTensor([self.labels[idx]])\n",
    "\n",
    "        try:\n",
    "            audio, sr = librosa.load(audio_path, sr=16000)\n",
    "            audio = librosa.util.fix_length(audio, size=self.target_length)\n",
    "\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=audio, sr=sr, \n",
    "                n_mfcc=self.n_mfcc,\n",
    "                n_fft=512,\n",
    "                hop_length=160\n",
    "            )\n",
    "\n",
    "            # Pad or truncate\n",
    "            if mfcc.shape[1] < self.fixed_time_steps:\n",
    "                mfcc = np.pad(mfcc, ((0, 0), (0, self.fixed_time_steps - mfcc.shape[1])))\n",
    "            else:\n",
    "                mfcc = mfcc[:, :self.fixed_time_steps]\n",
    "\n",
    "            mfcc_tensor = torch.FloatTensor(mfcc)  # Shape: [20, 101]\n",
    "\n",
    "            return mfcc_tensor, label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing file: {audio_path}\")\n",
    "            print(f\"âš ï¸ Exception: {e}\")\n",
    "            return None\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AudioDataset(train_real_directory, train_fake_directory)\n",
    "validation_dataset = AudioDataset(validation_real_directory, validation_fake_directory)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"âœ… Training & Validation Data Loaded Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Validation Accuracy: 96.36%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mfcc, labels in validation_loader:  # Now validation_loader exists âœ…\n",
    "        mfcc = mfcc.unsqueeze(1).to(device)  # Add channel dimension\n",
    "        labels = labels.squeeze().to(device)\n",
    "\n",
    "        outputs = model(mfcc)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"ðŸ“Š Validation Accuracy: {accuracy:.2f}%\")  # Now this will work âœ…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"C:/Users/shikh/OneDrive/Desktop/Audio Detection/audio_detection_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"âœ… Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"âœ… Model saved successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ Prediction for C:\\Users\\shikh\\OneDrive\\Desktop\\Audio Detection\\dataset\\for-2sec\\for-2seconds\\testing\\fake\\file42.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav: Fake\n"
     ]
    }
   ],
   "source": [
    "def predict_audio(audio_path, model, device):\n",
    "    model.eval()\n",
    "    try:\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        audio = librosa.util.fix_length(audio, size=16000)\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20, n_fft=512, hop_length=160)\n",
    "\n",
    "        if mfcc.shape[1] < 101:\n",
    "            mfcc = np.pad(mfcc, ((0, 0), (0, 101 - mfcc.shape[1])))\n",
    "        else:\n",
    "            mfcc = mfcc[:, :101]\n",
    "\n",
    "        mfcc_tensor = torch.FloatTensor(mfcc).unsqueeze(0).unsqueeze(0).to(device)  # Add batch & channel\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(mfcc_tensor)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "        return \"Fake\" if predicted.item() == 1 else \"Real\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ðŸ”¹ Example Usage:\n",
    "audio_file = r\"C:\\Users\\shikh\\OneDrive\\Desktop\\Audio Detection\\dataset\\for-2sec\\for-2seconds\\testing\\fake\\file42.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\"\n",
    "prediction = predict_audio(audio_file, model, device)\n",
    "print(f\"ðŸ§ Prediction for {audio_file}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Directory 'saved_models' is ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"saved_models\"  # Directory where the model will be saved\n",
    "os.makedirs(save_dir, exist_ok=True)  # âœ… Create folder if it doesn't exist\n",
    "\n",
    "print(f\"âœ… Directory '{save_dir}' is ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FakeAudioDetector(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=4000, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)  # âœ… Check if the model is defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved successfully at: saved_models/audio_detection_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "save_path = \"saved_models/audio_detection_model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(\"âœ… Model saved successfully at:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mfcc, labels in validation_loader:  # Use the validation/test loader\n",
    "        mfcc = mfcc.unsqueeze(1).to(device)  \n",
    "        labels = labels.squeeze().to(device)  \n",
    "\n",
    "        outputs = model(mfcc)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())  # Convert to NumPy array\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert to NumPy arrays for scikit-learn functions\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Define class labels (0 = Real, 1 = Fake)\n",
    "class_labels = [\"Real\", \"Fake\"]\n",
    "\n",
    "# Plot the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
